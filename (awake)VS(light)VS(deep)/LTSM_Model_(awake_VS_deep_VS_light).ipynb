{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IItbLHQxEUhY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Flatten\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GTYBn-iMWrg",
        "outputId": "0f4b5265-6bf9-425c-b9c0-abea2c0df1ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to your data directory\n",
        "data_directory = '/content/drive/My Drive/data'\n",
        "# Function to calculate SDNN from heart rate data\n",
        "def calculate_sdnn(heart_rate_values, window_size=5):\n",
        "    # Convert heart rate to RR intervals (assuming constant heart rate for simplicity)\n",
        "    rr_intervals = 60 / heart_rate_values  # since values are in bpm\n",
        "\n",
        "    # Calculate SDNN over a moving window\n",
        "    sdnn_values = []\n",
        "    for i in range(len(rr_intervals) - window_size + 1):\n",
        "        sdnn_values.append(np.std(rr_intervals[i:i+window_size]))\n",
        "\n",
        "    return np.array(sdnn_values)\n",
        "\n",
        "# Modified function to load and preprocess heart rate data\n",
        "def load_and_preprocess_heartrate(subject_id):\n",
        "    file_path = os.path.join(data_directory, 'heart_rate', f'{subject_id}_heartrate.txt')\n",
        "    data = pd.read_csv(file_path, header=None, names=['date', 'heartrate'])\n",
        "    heartrate_values = data['heartrate']\n",
        "\n",
        "    # Calculate SDNN from heart rate data\n",
        "    sdnn_values = calculate_sdnn(heartrate_values)\n",
        "\n",
        "    return sdnn_values\n",
        "\n",
        "def load_labeled_sleep(subject_id):\n",
        "    file_path = os.path.join(data_directory, 'labels', f'{subject_id}_labeled_sleep.txt')\n",
        "    data = pd.read_csv(file_path, header=None, delim_whitespace=True, names=['date', 'stage'])\n",
        "    # Encode sleep labels as 0 for awake, 1 for light sleep, and 2 for deep sleep\n",
        "    data['stage'] = data['stage'].map({0: 0, 1: 1, 2: 1, 3: 2, 5: 2})  # N1 and N2 as light sleep, N3 as deep sleep\n",
        "    return data['stage'].values\n",
        "\n",
        "subject_ids = [file.split('_')[0] for file in os.listdir(os.path.join(data_directory, 'labels')) if '_labeled_sleep.txt' in file]\n",
        "\n",
        "X_heartrate = []\n",
        "y_sleep = []\n",
        "\n",
        "sequence_length = 50\n",
        "\n",
        "for subject_id in subject_ids:\n",
        "    heartrate_values = load_and_preprocess_heartrate(subject_id)\n",
        "    sleep_labels = load_labeled_sleep(subject_id)\n",
        "\n",
        "    for i in range(0, len(heartrate_values) - sequence_length):\n",
        "        X_heartrate.append(heartrate_values[i:i+sequence_length])\n",
        "        y_sleep.append(sleep_labels[min(i+sequence_length-1, len(sleep_labels)-1)])"
      ],
      "metadata": {
        "id": "jgdSFr11Ec95"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_heartrate = np.array(X_heartrate)\n",
        "y_sleep = np.array(y_sleep)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_sleep = label_encoder.fit_transform(y_sleep)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_heartrate_scaled = scaler.fit_transform(X_heartrate)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_heartrate_scaled, y_sleep, test_size=0.1, random_state=42\n",
        ")\n",
        "print(\"Unique labels in y_train:\", np.unique(y_train))\n",
        "print(\"Unique labels in y_test:\", np.unique(y_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "5Lq9btTbEj7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ce93b2-b5d8-428b-c9e0-3dc1ba90b9d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in y_train: [0 1 2 3]\n",
            "Unique labels in y_test: [0 1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate labels 2 and 3 into a single class\n",
        "y_train[y_train == 3] = 2\n",
        "y_test[y_test == 3] = 2\n",
        "# Adjusting the number of output classes\n",
        "num_classes = 3\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential([\n",
        "    LSTM(units=100, input_shape=(sequence_length, 1), return_sequences=True),\n",
        "    LSTM(units=50, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')  # Softmax activation for multi-class classification\n",
        "])\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "# Model compilation\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    X_train[..., np.newaxis],  # Expand dimension for LSTM input shape\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "\n",
        "# Model evaluation\n",
        "y_pred = model.predict(X_test[..., np.newaxis])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "pfyn98VKEmXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bbbde3-6f84-4586-c10e-96e10302450d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6398/6398 [==============================] - 489s 68ms/step - loss: 0.9270 - accuracy: 0.5946 - val_loss: 0.9082 - val_accuracy: 0.5922\n",
            "Epoch 2/20\n",
            "6398/6398 [==============================] - 438s 68ms/step - loss: 0.8957 - accuracy: 0.6013 - val_loss: 0.8778 - val_accuracy: 0.6066\n",
            "Epoch 3/20\n",
            "6398/6398 [==============================] - 435s 68ms/step - loss: 0.8434 - accuracy: 0.6251 - val_loss: 0.8072 - val_accuracy: 0.6441\n",
            "Epoch 4/20\n",
            "6398/6398 [==============================] - 437s 68ms/step - loss: 0.7461 - accuracy: 0.6721 - val_loss: 0.7054 - val_accuracy: 0.6920\n",
            "Epoch 5/20\n",
            "6398/6398 [==============================] - 437s 68ms/step - loss: 0.6183 - accuracy: 0.7331 - val_loss: 0.5830 - val_accuracy: 0.7513\n",
            "Epoch 6/20\n",
            "6398/6398 [==============================] - 440s 69ms/step - loss: 0.4920 - accuracy: 0.7935 - val_loss: 0.4469 - val_accuracy: 0.8195\n",
            "Epoch 7/20\n",
            "6398/6398 [==============================] - 411s 64ms/step - loss: 0.3854 - accuracy: 0.8424 - val_loss: 0.3693 - val_accuracy: 0.8528\n",
            "Epoch 8/20\n",
            "6398/6398 [==============================] - 439s 69ms/step - loss: 0.3053 - accuracy: 0.8788 - val_loss: 0.3114 - val_accuracy: 0.8775\n",
            "Epoch 9/20\n",
            "6398/6398 [==============================] - 439s 69ms/step - loss: 0.2431 - accuracy: 0.9055 - val_loss: 0.2471 - val_accuracy: 0.9051\n",
            "Epoch 10/20\n",
            "6398/6398 [==============================] - 436s 68ms/step - loss: 0.2010 - accuracy: 0.9234 - val_loss: 0.2171 - val_accuracy: 0.9178\n",
            "Epoch 11/20\n",
            "6398/6398 [==============================] - 441s 69ms/step - loss: 0.1714 - accuracy: 0.9358 - val_loss: 0.1898 - val_accuracy: 0.9284\n",
            "Epoch 12/20\n",
            "6398/6398 [==============================] - 435s 68ms/step - loss: 0.1495 - accuracy: 0.9448 - val_loss: 0.1908 - val_accuracy: 0.9314\n",
            "Epoch 13/20\n",
            "6398/6398 [==============================] - 434s 68ms/step - loss: 0.1317 - accuracy: 0.9514 - val_loss: 0.1708 - val_accuracy: 0.9371\n",
            "Epoch 14/20\n",
            "6398/6398 [==============================] - 437s 68ms/step - loss: 0.1188 - accuracy: 0.9564 - val_loss: 0.1472 - val_accuracy: 0.9461\n",
            "Epoch 15/20\n",
            "6398/6398 [==============================] - 430s 67ms/step - loss: 0.1092 - accuracy: 0.9597 - val_loss: 0.1566 - val_accuracy: 0.9436\n",
            "Epoch 16/20\n",
            "6398/6398 [==============================] - 432s 67ms/step - loss: 0.1003 - accuracy: 0.9633 - val_loss: 0.1400 - val_accuracy: 0.9522\n",
            "Epoch 17/20\n",
            "6398/6398 [==============================] - 449s 70ms/step - loss: 0.0941 - accuracy: 0.9650 - val_loss: 0.1677 - val_accuracy: 0.9410\n",
            "Epoch 18/20\n",
            "6398/6398 [==============================] - 465s 73ms/step - loss: 0.0871 - accuracy: 0.9681 - val_loss: 0.1495 - val_accuracy: 0.9483\n",
            "Epoch 19/20\n",
            "6398/6398 [==============================] - 447s 70ms/step - loss: 0.0824 - accuracy: 0.9693 - val_loss: 0.1235 - val_accuracy: 0.9568\n",
            "Epoch 20/20\n",
            "6398/6398 [==============================] - 435s 68ms/step - loss: 0.0777 - accuracy: 0.9707 - val_loss: 0.1230 - val_accuracy: 0.9574\n",
            "790/790 [==============================] - 19s 23ms/step\n",
            "Test Accuracy: 0.9567969615445482\n"
          ]
        }
      ]
    }
  ]
}